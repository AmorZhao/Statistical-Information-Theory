{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "841e49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e593c2a0",
   "metadata": {},
   "source": [
    "# Tutorial 2\n",
    "## Shannon codes\n",
    "\n",
    "The year is 2148. In this future, the world has changed. Few things of the past are now remembered. The technocracy has taken over and our access to information has become fully controlled and obfuscated. All we know, is what we are told, and we are told very little.\n",
    "\n",
    "You are part of the Resistance, whose purpose is to Liberate Information. The Resistance follows the percepts of a very important manifesto, known as [\"The Mathematical Theory of Communication\"](https://archive.org/details/ost-engineering-shannon1948), a 200-year old text which contains the necessary and sufficient knowledge to setup communication systems, which has been recovered from the vaults of the corporations at great costs. Your goal is to share this text with other Resistance members everywhere in the world by broadcasting the text, in a loop, until the heat death of the universe.\n",
    "\n",
    "The only thing that's left is to encode it. You must use a code that is easy to revert. Someone suggested Morse code, but this is too inefficient: you have to add punctuation or spaces to help decoding. This means that no codeword should be the prefix of another.  A code with these properties is defined in the very text you must share:\n",
    "\n",
    "\n",
    "> Arrange the messages of length N in order of decreasing probability and suppose their probabilities are\n",
    "$p_1 \\le p_2 \\le  ... p_n$. Let $P_s = \\sum_1^{s-1} p_i$; that is $P_s$ is the cumulative probability up to, but not including, $p_s$.\n",
    "We first encode into a binary system. The binary code for message s is obtained by expanding $P_s$ as a binary number. The expansion is carried out to $m_s$ places, where $m_s$ is the integer satisfying:\n",
    "$$log_2 \\frac{1}{p_s} \\le m_s \\le 1 + \\log_2 \\frac{1}{p_s}$$\n",
    "Thus the messages of high probability are represented by short codes and those of low probability by long codes.\n",
    "\n",
    "## Your task\n",
    "Members of the Resistance already have transmitters and receivers, but don't know how to use them. Your task is to help them encode and decode \"The Mathematical Theory of Communication\" using the Shannon code defined above. Suppose the alphabet is the alphanumerics (all lowercase): to make it easier, the function `infinite_shannon()` loads the paper in plain text for you and removes all non-alphanumeric characters.\n",
    "\n",
    "\n",
    "#### Bonus\n",
    "For the purpose of this exercise, we ignore mathematical symbols, but you may try including them - how much bigger does the code get?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "14167970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "from math import log2, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c551ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = \"abcdefghijklmnopqrstuvwxyz01234567890\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53628b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinite_shannon() -> str:\n",
    "\n",
    "    text = ''\n",
    "    with open('shannon1948.txt', 'r') as f:\n",
    "        text = f.read()\n",
    "    text = text.lower()\n",
    "    text = [ t for t in text if t in alphabet ]\n",
    "    return text\n",
    "\n",
    "text = infinite_shannon()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350f9de1",
   "metadata": {},
   "source": [
    "### Step 1: Cumulative probability\n",
    "First step is to obtain the probability distributions of each symbol from the text, and then compute the cumulative probability distribution. For convenience, you should first re-order the symbols by their frequency (most frequent first, by using `sorted(list, reverse=True)`), or by using an `OrderedDict`. You may want to plot the cumulative distribution to make sure you obtain the discrete staircase shape.\n",
    "\n",
    "Hint: Frequency counting can be easily done in 'vanilla' Python using `collections.Counter`. You don't have to, but you can use `cumsum` in `numpy` to compute cumulative distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f23cf4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freqs(text: str) -> Dict[chr, int]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "def cum_prob(freqs: Dict[chr, int]) -> Dict[chr, float]:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840476d7",
   "metadata": {},
   "source": [
    "### Step 2: Binary encoding\n",
    "Now use binary encoding to encode the cumulative probability, $F(x_i)$ (or $P_i$ in Shannon's notation), then take the first $\\ell(x_i) = \\lceil \\frac{1}{p(x_i)} \\rceil$ digits (or $m_s$) from it to obtain the codeword. \n",
    "\n",
    "If you haven't seen this before, binary encoding can be done for non-integers too! For example:\n",
    "\n",
    "- 0.1 = one half\n",
    "- 0.01 = one fourth\n",
    "- 0.001 = one eighth\n",
    "- 0.101 = five eighths\n",
    "- 0.1111 = fifteen sixteenths\n",
    "\n",
    "Hint: If encoding a decimal integer into binary is done by iteratively dividing by 2 repeatedly and taking the remainders until the quotient remains 0, encoding the decimal fractional is done by iteratively multiplying the fractional part by 2 and taking the integral part of the result, until the fractional part remains 0. \n",
    "\n",
    "It's easiest to operate with strings, and to build a dictionary that returns a codeword for each character in the alphabet, but implementation details are up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "13b14193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary(f: float) -> str:\n",
    "    raise NotImplementedError\n",
    "\n",
    "def get_shannon_codeword(p: float, f: float) -> str:\n",
    "    raise NotImplementedError\n",
    "\n",
    "def shannon_code_dict(freqs: Dict[chr, int]) -> Dict[chr, str]:\n",
    "    f = cum_prob(freqs)\n",
    "    \n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04913c",
   "metadata": {},
   "source": [
    "Now to put it all together! The function below is meant to extract the probabilities from the given text, then produce a code dictionary that you can use to encode (and decode!) the text.\n",
    "\n",
    "Alternatively, you could pass in a code dictionary, and encode a (possibly different) text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "96e38bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_encode(text: str) -> str:\n",
    "    freqs = get_freqs(text)\n",
    "    codes = shannon_code_dict(freqs)\n",
    "    \n",
    "    return [ codes[x] for x in text ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a93076f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text: str, codes: Dict[chr, str]) -> str:\n",
    "    \n",
    "    return [ codes[x] for x in text ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0cd10c",
   "metadata": {},
   "source": [
    "### Step 3: Binary decoding\n",
    "\n",
    "Now you must help the other members of the resistance with the decoding. Given a sequence in the Shannon code, can you write a function to decode it back to English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7994a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(coded: str, codes: Dict[chr, str]) -> str:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dc7ff9",
   "metadata": {},
   "source": [
    "### Examples \n",
    "\n",
    "You may want to test your implementation first. Here is an example from Shannon's paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "086ffd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictify(keys: List[Any], values: List[Any]) -> Dict[Any, Any]:\n",
    "    return dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75a8b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example():\n",
    "    alph = [ 'a', 'b', 'c', 'd' ]\n",
    "    prob = [ 1/2, 1/4, 1/8, 1/8 ]\n",
    "    code = [ '0', '10', '110', '111' ] \n",
    "    \n",
    "    return dictify(alph, prob), dictify(alph, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a37d6",
   "metadata": {},
   "source": [
    "And here is someting to decode! \n",
    "c = `0110010011001001100100110010`\n",
    "\n",
    "Try both using the dictionary from `example()` or using the `c` string as text, deriving probabilities from it. How do the codes differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9ca9ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = '0110010011001001100100110010'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2751b6d",
   "metadata": {},
   "source": [
    "### Testing your code\n",
    "A few sanity checks... you want to check all codewords are different from each other, that none of them is the prefix of another, and that the length of the codes is higher than the entropy. You can apply the functions below to the list of unique codewords to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "534b8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __unique(codes: List[str]) -> bool:\n",
    "    \n",
    "    return sorted(codes) == sorted(set(codes))\n",
    "\n",
    "def __prefix_free(codes: List[str]) -> bool:\n",
    "    \n",
    "    for c in codes:\n",
    "        if any([d.startswith(c) for d in codes]):\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "def __entropy(probs: List[str], codes: List[str]) -> bool:\n",
    "    \n",
    "    H = sum( -p * log2(p) for p in probs )\n",
    "    print(f\"Entropy of the distribution is: {H}\")\n",
    "    L = 1/len(codes) * sum( len(c) for c in codes)\n",
    "    print(f\"Mean code length: {L}\")\n",
    "    \n",
    "    return H < L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91e023",
   "metadata": {},
   "source": [
    "And now, are you ready to encode the Shannon text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = get_freqs(text)\n",
    "codes = code_dict(freqs)\n",
    "coded = encode(text, codes)\n",
    "\n",
    "text2 = decode(coded, codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4bb49",
   "metadata": {},
   "source": [
    "Does the decoded text match the original?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "text == text2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee0bbc",
   "metadata": {},
   "source": [
    "## Huffman code\n",
    "\n",
    "The year is 2152. You succeeded in your mission, and the Resistance's communications and research has started growing exponentially. Now many more codes have been unearthed and are being reimplemented. Developments in Free Information Theory have revealed the most efficient form of a symbol code is what is called the Huffman code. As a hero of the Resistance, you've been asked to update the beacon and send the Shannon paper this time in the Huffman code.\n",
    "\n",
    "The Huffman code, recovered from a lost scroll from 200 years ago called [\"A Method for the Construction of Minimum-Redundancy Codes\"](http://compression.ru/download/articles/huff/huffman_1952_minimum-redundancy-codes.pdf), works as follows:\n",
    "\n",
    "1. Pick the last 2 probable symbols\n",
    "2. Combine them into a single symbol, forming a binary tree\n",
    "3. If more than one symbol remains, go to step 1.\n",
    "\n",
    "\n",
    "### Step 1: build tree\n",
    "The tree is built incrementally from the symbols, starting with the least frequent. You can use the same `get_freqs` from the Shannon code (Huffman encoding doesn't care if you pass in probabilities or frequencies, but make sure they are storted).\n",
    "\n",
    "To build and traverse  trees, you may find a node data structure useful, such as the one below.\n",
    "\n",
    "The nodes either have children, or they are a leaf, thus having a label that represents the string being encoded. A link to the parent node can help with traversing it up and down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "85fdb2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, l: 'Node' = None, r: 'Node' = None,\n",
    "                       p: 'Node '= None, lab: str = ''):\n",
    "        self.l = l\n",
    "        self.r = r\n",
    "        self.p = p\n",
    "        self.lab = lab\n",
    "\n",
    "    def children(self):\n",
    "        return self.l, self.r\n",
    "    \n",
    "    def parent(self):\n",
    "        return self.p\n",
    "    \n",
    "    def __str__(self):\n",
    "        if self.lab:\n",
    "            return self.lab\n",
    "        else:\n",
    "            return f\"(L: {str(self.l)}, R: {str(self.r)})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdf1b25",
   "metadata": {},
   "source": [
    "For example, this tree\n",
    "\n",
    "![](huffman-tree-example1.png)\n",
    "\n",
    "could be expressed as (ignoring parents):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5dfad932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(L: (L: a, R: (L: d, R: e)), R: (L: b, R: c))\n"
     ]
    }
   ],
   "source": [
    "root = Node(\n",
    "    l = Node(\n",
    "            l = Node(lab = 'a'),\n",
    "            r = Node(\n",
    "                l = Node(lab = 'd'),\n",
    "                r = Node(lab = 'e')\n",
    "            )\n",
    "        ),\n",
    "    r = Node(\n",
    "            l = Node(lab = 'b'),\n",
    "            r = Node(lab = 'c')\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b92f5",
   "metadata": {},
   "source": [
    "After building the tree, you can either obtain a root node with links to the children, as in the example above, or you can have a list of leaves for each codewords, with links to the parents.\n",
    "\n",
    "Now it's time for you to build the Huffman code tree. There are many ways of doing this, but you may find the following steps useful:\n",
    "1. Create one leaf node for each symbol in the alphabet, and sort these nodes in a list according to the probability of their corresponding label.\n",
    "2. Create a new node that acts as the parent of the two nodes with least probability, and assign to the new node the sum of those two probabilities.\n",
    "3. Add the new node to the list and remove the two nodes that have just been merged.\n",
    "4. Repeat from step 2 as necessary.\n",
    "\n",
    "Go on, now. The Resistance needs you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d1cda413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(freqs: Dict[chr, float]) -> 'Node':\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98843ae",
   "metadata": {},
   "source": [
    "### Step 2: find code\n",
    "\n",
    "The code can be constructed by 'traversing' the tree. Depending on your implementation, one simple way to do this would be to start at the root, and descend recursively until you reach the leaf, in a way similar to the `__str__` function the node uses to print the tree. The code will contain a `0` if the symbol is in the left subtree, and a `1` if the symbol is in the right subtree.\n",
    "\n",
    "Regardless of your implementation, you likely want to produce a dictionary that maps each symbol to a codeword, similar to the Shannon code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "520fc820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_code_dict(tree: 'Node') -> Dict[chr, str]:\n",
    "    raise NotImplementedError  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8ad14",
   "metadata": {},
   "source": [
    "Now in a similar way to the Shannon code, we put it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2434f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_encode(text: str) -> str:\n",
    "    freqs = get_freqs(text)\n",
    "    tree  = build_tree(freqs)\n",
    "    codes = huffman_code_dict(tree)\n",
    "    \n",
    "    return [ codes[x] for x in text ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf8071",
   "metadata": {},
   "source": [
    "Once you obtain the dictionary of codes, you should be able to use  the same `encode` and `decode` functions from the Shannon codes, by passing them a text and a code dictionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aae013",
   "metadata": {},
   "source": [
    "### Examples \n",
    "\n",
    "You may want to test your implementation first. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b280c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example1():\n",
    "    alph = [ 'a', 'b', 'c', 'd', 'e' ]\n",
    "    prob = [ 1/4, 1/4, 1/5, 3/20, 3/20 ]\n",
    "    code = [ '00', '10', '11', '010', '011' ] \n",
    "    \n",
    "    return dictify(alph, prob), dictify(alph, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f378d",
   "metadata": {},
   "source": [
    "And another, taken directly from Huffman's paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0670b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example2():\n",
    "    alph = range(1, 14)\n",
    "    prob = [ 0.2, 0.18, 0.1, 0.1, 0.1, 0.05, 0.06, 0.04, 0.04, 0.04, 0.04, 0.03, 0.01 ]\n",
    "    code = [ '10', '000', '011', '110', '111', '0101', '00100', \n",
    "            '00101', '01000', '01001', '00110', '001110', '001111']\n",
    "    \n",
    "    return dictify(alph, prob), dictify(alph, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a0f04",
   "metadata": {},
   "source": [
    "You should, of course, use the sanity check functions `__unique` and `__prefix_free`.\n",
    "\n",
    "_How does the entropy check change for the Huffman code?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1094d5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6435278",
   "metadata": {},
   "source": [
    "\n",
    "You may notice that the code your algorithm produced has all the necessary properties but **is not the same** as the one in the example. Don't despair! You have just discovered that the optimal Huffman encoding is not always unique! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef1b230",
   "metadata": {},
   "source": [
    "_Don't forget to encode the Shannon paper! How much more efficient is the Huffman code?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5482253d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
